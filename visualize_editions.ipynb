{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d1f436",
   "metadata": {},
   "source": [
    "# Visualization of Edition Differences\n",
    "\n",
    "![screenshot of the visualizations](./img/header.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c97c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from germansentiment import SentimentModel\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedca14",
   "metadata": {},
   "source": [
    "In order to run this notebook, you will have to download the provided [sample dataset](https://doi.org/10.5281/zenodo.4992787) and extract it to a folder that will have to pass to the variable `baseDir`in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66ab66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ./analysis/\n"
     ]
    }
   ],
   "source": [
    "# path to the sbbget temporary result files, e.g. \"../sbbget/sbbget_downloads/download_temp\" (the base path under which ALTO files are stored)\n",
    "baseDir=\"/Users/david/src/python/StabiHacks/sbbget/sbbget_downloads.div_spielebuecher/download_temp/\"\n",
    "\n",
    "# path of the analysis results\n",
    "analysisPath=\"./analysis/\"\n",
    "# verbose output\n",
    "verbose=True\n",
    "\n",
    "def printLog(text):\n",
    "    now = str(datetime.now())\n",
    "    print(\"[\" + now + \"]\\t\" + text)\n",
    "    # forces to output the result of the print command immediately, see: http://stackoverflow.com/questions/230751/how-to-flush-output-of-python-print\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def createSupplementaryDirectories():\n",
    "    if not os.path.exists(analysisPath):\n",
    "        if verbose:\n",
    "            print(\"Creating \" + analysisPath)\n",
    "        os.mkdir(analysisPath)\n",
    "\n",
    "createSupplementaryDirectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730ed41",
   "metadata": {},
   "source": [
    "## METS/MODS Processing\n",
    "\n",
    "The next cell contains the logic to parse a METS/MODS XML file and save its contents to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1b1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML namespace of MODS\n",
    "modsNamespace = \"{http://www.loc.gov/mods/v3}\"\n",
    "\n",
    "def parseOriginInfo(child):\n",
    "    \"\"\"\n",
    "    Parses an originInfo node and its children\n",
    "    :param child: The originInfo child in the element tree.\n",
    "    :return: A dict with the parsed information or None if the originInfo is invalid.\n",
    "    \"\"\"\n",
    "    discardNode = True\n",
    "\n",
    "    result = dict()\n",
    "    result[\"publisher\"] = \"\"\n",
    "    # check if we can directly process the node\n",
    "    if \"eventType\" in child.attrib:\n",
    "        if child.attrib[\"eventType\"] == \"publication\":\n",
    "            discardNode = False\n",
    "    else:\n",
    "        # we have to check if the originInfo contains and edition node with \"[Electronic ed.]\" to discard the node\n",
    "        children = child.getchildren()\n",
    "        hasEdition = False\n",
    "        for c in children:\n",
    "            if c.tag == modsNamespace + \"edition\":\n",
    "                hasEdition = True\n",
    "                if c.text == \"[Electronic ed.]\":\n",
    "                    discardNode = True\n",
    "                else:\n",
    "                    discardNode = False\n",
    "        if not hasEdition:\n",
    "            discardNode = False\n",
    "\n",
    "    if discardNode:\n",
    "        return None\n",
    "    else:\n",
    "        for c in child.getchildren():\n",
    "            cleanedTag = c.tag.replace(modsNamespace, \"\")\n",
    "            if cleanedTag == \"place\":\n",
    "                result[\"place\"] = c.find(\"{http://www.loc.gov/mods/v3}placeTerm\").text.strip()\n",
    "            if cleanedTag == \"publisher\":\n",
    "                result[\"publisher\"] = c.text.strip()\n",
    "            # check for the most important date (see https://www.loc.gov/standards/mods/userguide/origininfo.html)\n",
    "            if \"keyDate\" in c.attrib:\n",
    "                result[\"date\"] = c.text.strip()\n",
    "    return result\n",
    "\n",
    "def parseTitleInfo(child):\n",
    "    result = dict()\n",
    "    result[\"title\"]=\"\"\n",
    "    result[\"subTitle\"]=\"\"\n",
    "\n",
    "    for c in child.getchildren():\n",
    "        cleanedTag = c.tag.replace(modsNamespace, \"\")\n",
    "        result[cleanedTag]=c.text.strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "def parseLanguage(child):\n",
    "    result = dict()\n",
    "    result[\"language\"]=\"\"\n",
    "\n",
    "    for c in child.getchildren():\n",
    "        cleanedTag = c.tag.replace(modsNamespace, \"\")\n",
    "        if cleanedTag==\"languageTerm\":\n",
    "            result[\"language\"]=c.text.strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "def parseName(child):\n",
    "    result=dict()\n",
    "    role=\"\"\n",
    "    name=\"\"\n",
    "    for c in child.getchildren():\n",
    "        cleanedTag = c.tag.replace(modsNamespace, \"\")\n",
    "        if cleanedTag==\"role\":\n",
    "            for c2 in c.getchildren():\n",
    "                ct=c2.tag.replace(modsNamespace, \"\")\n",
    "                if ct==\"roleTerm\":\n",
    "                    role=c2.text.strip()\n",
    "        elif cleanedTag==\"displayForm\":\n",
    "            name=c.text.strip()\n",
    "    result[role]=name\n",
    "    return result\n",
    "\n",
    "def parseAccessCondition(child):\n",
    "    result = dict()\n",
    "    result[\"access\"]=child.text.strip()\n",
    "    return result\n",
    "\n",
    "def processMETSMODS(currentPPN, metsModsPath):\n",
    "    \"\"\"\n",
    "    Processes a given METS/MODS file.\n",
    "    :param currentPPN: the current PPN\n",
    "    :param metsModsPath: path to the METS/MODS file\n",
    "\n",
    "    :return: A dataframe with the parsing results.\n",
    "    \"\"\"\n",
    "    # parse the METS/MODS file\n",
    "    tree = ET.parse(metsModsPath)\n",
    "    root = tree.getroot()\n",
    "    # only process possibly interesting nodes, i.e.,\n",
    "    nodesOfInterest = [\"originInfo\", \"titleInfo\", \"language\", \"name\", \"accessCondition\"]\n",
    "\n",
    "    # stores result dicts created by various parsing function (see below)\n",
    "    resultDicts=[]\n",
    "    # master dictionary, later used for the creation of a dataframe\n",
    "    masterDict={'publisher':\"\",'place':\"\",'date':\"\",'title':\"\",'subTitle':\"\",'language':\"\",'aut':\"\",'rcp':\"\",'fnd':\"\",'access':\"\",'altoPaths':\"\"}\n",
    "    # find all mods:mods nodes\n",
    "    for modsNode in root.iter(modsNamespace + 'mods'):\n",
    "        for child in modsNode:\n",
    "            # strip the namespace\n",
    "            cleanedTag = child.tag.replace(modsNamespace, \"\")\n",
    "            #print(cleanedTag)\n",
    "            #print(child)\n",
    "            if cleanedTag in nodesOfInterest:\n",
    "                if cleanedTag == \"originInfo\":\n",
    "                    r = parseOriginInfo(child)\n",
    "                    if r:\n",
    "                        resultDicts.append(r)\n",
    "                elif cleanedTag==\"titleInfo\":\n",
    "                    r = parseTitleInfo(child)\n",
    "                    if r:\n",
    "                        resultDicts.append(r)\n",
    "                elif cleanedTag==\"language\":\n",
    "                    r = parseLanguage(child)\n",
    "                    if r:\n",
    "                        resultDicts.append(r)\n",
    "                elif cleanedTag==\"name\":\n",
    "                    r = parseName(child)\n",
    "                    if r:\n",
    "                        resultDicts.append(r)\n",
    "                elif cleanedTag==\"accessCondition\":\n",
    "                    r = parseAccessCondition(child)\n",
    "                    if r:\n",
    "                        resultDicts.append(r)\n",
    "        # we are only interested in the first occuring mods:mods node\n",
    "        break\n",
    "\n",
    "    resultDicts.append(r)\n",
    "\n",
    "    # copy results to the master dictionary\n",
    "    for result in resultDicts:\n",
    "        for key in result:\n",
    "            masterDict[key]=[result[key]]\n",
    "    masterDict[\"ppn\"]=[currentPPN]\n",
    "    return pd.DataFrame(data=masterDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b36eea",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "The following cell is based on https://github.com/oliverguhr/german-sentiment-lib. The small fix in line 28 has been offered as a pull request to the original author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21bc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import List\n",
    "import torch\n",
    "import re\n",
    "\n",
    "class SentimentModel_dazFix():\n",
    "    def __init__(self, model_name: str = \"oliverguhr/german-sentiment-bert\"):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'        \n",
    "            \n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r'https*\\S+', re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r'@\\S+', re.MULTILINE)\n",
    "\n",
    "    def predict_sentiment(self, texts: List[str])-> List[str]:\n",
    "        texts = [self.clean_text(text) for text in texts]\n",
    "        # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        # daz: last two parameters added to limit maximum number of tokens in case of long strings and to prevent crashes\n",
    "        # such as:\n",
    "        #\"Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). \n",
    "        # Running this sequence through the model will result in indexing errors\"\n",
    "        input_ids = self.tokenizer.batch_encode_plus(texts,padding=True, add_special_tokens=True,truncation=True,max_length=512)\n",
    "        input_ids = torch.tensor(input_ids[\"input_ids\"])\n",
    "        input_ids = input_ids.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_ids)    \n",
    "\n",
    "        label_ids = torch.argmax(logits[0], axis=1)\n",
    "\n",
    "        labels = [self.model.config.id2label[label_id] for label_id in label_ids.tolist()]\n",
    "        return labels\n",
    "\n",
    "    def replace_numbers(self,text: str) -> str:\n",
    "            return text.replace(\"0\",\" null\").replace(\"1\",\" eins\").replace(\"2\",\" zwei\")\\\n",
    "                .replace(\"3\",\" drei\").replace(\"4\",\" vier\").replace(\"5\",\" fünf\") \\\n",
    "                .replace(\"6\",\" sechs\").replace(\"7\",\" sieben\").replace(\"8\",\" acht\") \\\n",
    "                .replace(\"9\",\" neun\")         \n",
    "\n",
    "    def clean_text(self,text: str)-> str:    \n",
    "            text = text.replace(\"\\n\", \" \")        \n",
    "            text = self.clean_http_urls.sub('',text)\n",
    "            text = self.clean_at_mentions.sub('',text)        \n",
    "            text = self.replace_numbers(text)                \n",
    "            text = self.clean_chars.sub('', text) # use only text chars                          \n",
    "            text = ' '.join(text.split()) # substitute multiple whitespace with single whitespace   \n",
    "            text = text.strip().lower()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc4617",
   "metadata": {},
   "source": [
    "## Preparation of the Visualization\n",
    "\n",
    "The next cell will read in all images, their accompanying metadata from METS/MODS XML files and the associated fulltext data. A sentiment analysis will be carried out on the fulltexts. The sentiment analysis assumes German texts.\n",
    "Finally, records are created for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78402aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-06-19 17:35:45.140873]\tLoading sentiment model...\n",
      "[2021-06-19 17:35:50.051229]\tFetching files...\n",
      "[2021-06-19 17:35:50.052603]\tProcessing files for PPN: PPN745143385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5a0ce7673633>:35: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  for c in child.getchildren():\n",
      "<ipython-input-3-5a0ce7673633>:51: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  for c in child.getchildren():\n",
      "<ipython-input-3-5a0ce7673633>:61: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  for c in child.getchildren():\n",
      "<ipython-input-3-5a0ce7673633>:72: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  for c in child.getchildren():\n",
      "<ipython-input-3-5a0ce7673633>:75: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  for c2 in c.getchildren():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-06-19 17:38:53.911120]\tProcessing files for PPN: PPN745158323\n",
      "[2021-06-19 17:46:53.587373]\tProcessing files for PPN: PPN745183891\n",
      "[2021-06-19 17:50:57.997120]\tProcessing files for PPN: PPN74602598X\n",
      "[2021-06-19 18:04:29.943315]\tProcessing files for PPN: PPN745182844\n",
      "[2021-06-19 18:14:59.584201]\tProcessing files for PPN: PPN745846971\n",
      "[2021-06-19 18:29:49.130390]\tFound 1750 images.\n",
      "Started at:\t2021-06-19 17:35:45.140795\n",
      "Ended at:\t2021-06-19 18:29:49.131839\n"
     ]
    }
   ],
   "source": [
    "jpgFilePaths = dict()\n",
    "ppnDirs=[]\n",
    "rows=[]\n",
    "\n",
    "startTime = str(datetime.now())\n",
    "printLog(\"Loading sentiment model...\")\n",
    "model = SentimentModel_dazFix()\n",
    "\n",
    "printLog(\"Fetching files...\")\n",
    "# check all subdirectories startings with PPN as each PPN stands for a different medium        \n",
    "for x in os.listdir(baseDir):\n",
    "    if x.startswith(\"PPN\"):\n",
    "        ppnDirs.append(x)\n",
    "\n",
    "# browse all directories below sbbGetBasePath and search for *_FULLTEXT directories\n",
    "# and associate each with its PPN\n",
    "for ppn in ppnDirs:\n",
    "    printLog(\"Processing files for PPN: \"+ppn)\n",
    "    ppnRecord=dict()\n",
    "    \n",
    "    metsModsPath=baseDir+ppn+\"/__metsmods/\"+ppn+\".xml\"\n",
    "    r=processMETSMODS(\"PPNxyz\",metsModsPath)\n",
    "    ppnRecord[\"_place\"]=r[\"place\"].values[0]\n",
    "    ppnRecord[\"_title\"]=r[\"title\"].values[0]\n",
    "    ppnRecord[\"_publisher\"]=r[\"publisher\"].values[0]\n",
    "    ppnRecord[\"_date\"]=r[\"date\"].values[0]\n",
    "    \n",
    "                    \n",
    "    for dirpath, dirnames, files in os.walk(baseDir+ppn):\n",
    "        for name in files:\n",
    "            if dirpath.endswith(\"_TIFF\"):\n",
    "                record=dict()\n",
    "                # all relevant data is joined into the keywords field as Vikus will use this field for filtering\n",
    "                record[\"keywords\"]=\",\".join((ppn,ppnRecord[\"_place\"],ppnRecord[\"_title\"],ppnRecord[\"_publisher\"]+\" (Verlag)\",ppnRecord[\"_date\"]))\n",
    "                result=[]\n",
    "                # if we find no OCR data, we will save a placeholder text instead\n",
    "                description=\"Keine OCR-Ergebnisse vorhanden.\"\n",
    "                # if we found a image directory, only add JPEG files\n",
    "                if name.endswith(\".jpg\") or name.endswith(\".JPG\"):\n",
    "                    if not ppn in jpgFilePaths:\n",
    "                        jpgFilePaths[ppn]=[]\n",
    "                    fullJPGPath=os.path.join(dirpath, name)\n",
    "                    jpgFilePaths[ppn].append(fullJPGPath)\n",
    "                \n",
    "                    # get the raw fulltext\n",
    "                    rawTextPath=dirpath.replace(\"_TIFF\",\"_FULLTEXT\")+\"/\"\n",
    "                    t=rawTextPath.split(\"FILE_\")[1].split(\"_FULLTEXT\")\n",
    "                    txtFile=t[0].zfill(8)+\"_raw.txt\"\n",
    "                    rawTextPath+=txtFile\n",
    "                    \n",
    "                    if os.path.exists(rawTextPath):\n",
    "                        fileHandler = open(rawTextPath,mode='r')\n",
    "                        fulltext = fileHandler.read()\n",
    "                        if len(fulltext)>800:\n",
    "                            description=fulltext[:800]+\"[...]\"\n",
    "                        else:\n",
    "                            description=fulltext\n",
    "                        fileHandler.close()\n",
    "                        # sentiment analysis of the raw OCR fulltext\n",
    "                        result = model.predict_sentiment([fulltext])\n",
    "                           \n",
    "                    # get the physical page number of the current image\n",
    "                    txtFilePath=ppn+\".txt\"\n",
    "                    \n",
    "                    with open(os.path.join(dirpath, txtFilePath)) as txtFile:\n",
    "                        dest=\"\"\n",
    "                        for row in txtFile:\n",
    "                            logPage=row.split()[1]\n",
    "                            dest=analysisPath+ppn+\"_\"+logPage+\".jpg\"\n",
    "                            record[\"id\"]=ppn+\"_\"+logPage\n",
    "\n",
    "                            record[\"year\"]=math.ceil(int(logPage.split(\"_\")[1])/10)*10\n",
    "                            record[\"_realpage\"]=int(logPage.split(\"_\")[1])\n",
    "                            if result:\n",
    "                                record[\"_sentiment\"]=result[0]\n",
    "                                record[\"keywords\"]+=\",\"+result[0]+ \" (Sentiment)\"\n",
    "                            record[\"_description\"]=description\n",
    "\n",
    "                    #print(\"Copy from %s to %s\"%(fullJPGPath,dest))\n",
    "                    # copy the found files to a new location with new unique names as required by Vikus\n",
    "                    shutil.copy(fullJPGPath,dest)\n",
    "                    # \"join\" the current record with its surrounding PPN metadata\n",
    "                    record.update(ppnRecord)\n",
    "                    rows.append(record)\n",
    "                        \n",
    "sum=0\n",
    "for ppn in jpgFilePaths:\n",
    "    for f in jpgFilePaths[ppn]:\n",
    "        sum+=1\n",
    "printLog(\"Found %i images.\"%sum)\n",
    "endTime = str(datetime.now())\n",
    "print(\"Started at:\\t%s\\nEnded at:\\t%s\" % (startTime, endTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a87c7",
   "metadata": {},
   "source": [
    "In the next cell, a dataframe is created from the records. The resulting dataframe is then saved in a CSV file readable by Vikus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beaac2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>_realpage</th>\n",
       "      <th>_sentiment</th>\n",
       "      <th>_description</th>\n",
       "      <th>_place</th>\n",
       "      <th>_title</th>\n",
       "      <th>_publisher</th>\n",
       "      <th>_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PPN745143385,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745143385_PHYS_0011</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\nVII \\nSeite \\nGeschwindsprechsätze . 70 \\nKa...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Kinder</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PPN745143385,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745143385_PHYS_0046</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n34 \\nFlechtarbeit. \\nEine der schönsten und ...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Kinder</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PPN745143385,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745143385_PHYS_0103</td>\n",
       "      <td>110</td>\n",
       "      <td>103</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n91 \\nDer Reiter „ vom Ahornbaum. \\nDer Ahorn...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Kinder</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPN745143385,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745143385_PHYS_0050</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n38 \\nihren Puppen und sich selbst allerlei n...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Kinder</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPN745143385,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745143385_PHYS_0115</td>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n103 \\nhinausgeschossen hat. Der Treffer schi...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Kinder</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>PPN745846971,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745846971_PHYS_0317</td>\n",
       "      <td>320</td>\n",
       "      <td>317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keine OCR-Ergebnisse vorhanden.</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Knaben</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>PPN745846971,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745846971_PHYS_0069</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n49 \\n98] \\nSuch- und Ratespiele. \\ndes o ? '...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Knaben</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>PPN745846971,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745846971_PHYS_0086</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n66 Bewegungsspiele mit erforderlichem Spielg...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Knaben</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>PPN745846971,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745846971_PHYS_0205</td>\n",
       "      <td>210</td>\n",
       "      <td>205</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n360- \\n-362] \\nSchneespiele und Eisvergnügun...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Knaben</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>PPN745846971,Leipzig,Illustriertes Spielbuch f...</td>\n",
       "      <td>PPN745846971_PHYS_0340</td>\n",
       "      <td>340</td>\n",
       "      <td>340</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\\n308 \\nSprachspielc und Pfänderspiele. [579 \\...</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Illustriertes Spielbuch für Knaben</td>\n",
       "      <td>Spamer</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               keywords  \\\n",
       "0     PPN745143385,Leipzig,Illustriertes Spielbuch f...   \n",
       "1     PPN745143385,Leipzig,Illustriertes Spielbuch f...   \n",
       "2     PPN745143385,Leipzig,Illustriertes Spielbuch f...   \n",
       "3     PPN745143385,Leipzig,Illustriertes Spielbuch f...   \n",
       "4     PPN745143385,Leipzig,Illustriertes Spielbuch f...   \n",
       "...                                                 ...   \n",
       "1745  PPN745846971,Leipzig,Illustriertes Spielbuch f...   \n",
       "1746  PPN745846971,Leipzig,Illustriertes Spielbuch f...   \n",
       "1747  PPN745846971,Leipzig,Illustriertes Spielbuch f...   \n",
       "1748  PPN745846971,Leipzig,Illustriertes Spielbuch f...   \n",
       "1749  PPN745846971,Leipzig,Illustriertes Spielbuch f...   \n",
       "\n",
       "                          id  year  _realpage _sentiment  \\\n",
       "0     PPN745143385_PHYS_0011    20         11    neutral   \n",
       "1     PPN745143385_PHYS_0046    50         46    neutral   \n",
       "2     PPN745143385_PHYS_0103   110        103    neutral   \n",
       "3     PPN745143385_PHYS_0050    50         50    neutral   \n",
       "4     PPN745143385_PHYS_0115   120        115    neutral   \n",
       "...                      ...   ...        ...        ...   \n",
       "1745  PPN745846971_PHYS_0317   320        317        NaN   \n",
       "1746  PPN745846971_PHYS_0069    70         69    neutral   \n",
       "1747  PPN745846971_PHYS_0086    90         86    neutral   \n",
       "1748  PPN745846971_PHYS_0205   210        205    neutral   \n",
       "1749  PPN745846971_PHYS_0340   340        340    neutral   \n",
       "\n",
       "                                           _description   _place  \\\n",
       "0     \\nVII \\nSeite \\nGeschwindsprechsätze . 70 \\nKa...  Leipzig   \n",
       "1     \\n34 \\nFlechtarbeit. \\nEine der schönsten und ...  Leipzig   \n",
       "2     \\n91 \\nDer Reiter „ vom Ahornbaum. \\nDer Ahorn...  Leipzig   \n",
       "3     \\n38 \\nihren Puppen und sich selbst allerlei n...  Leipzig   \n",
       "4     \\n103 \\nhinausgeschossen hat. Der Treffer schi...  Leipzig   \n",
       "...                                                 ...      ...   \n",
       "1745                    Keine OCR-Ergebnisse vorhanden.  Leipzig   \n",
       "1746  \\n49 \\n98] \\nSuch- und Ratespiele. \\ndes o ? '...  Leipzig   \n",
       "1747  \\n66 Bewegungsspiele mit erforderlichem Spielg...  Leipzig   \n",
       "1748  \\n360- \\n-362] \\nSchneespiele und Eisvergnügun...  Leipzig   \n",
       "1749  \\n308 \\nSprachspielc und Pfänderspiele. [579 \\...  Leipzig   \n",
       "\n",
       "                                  _title _publisher _date  \n",
       "0     Illustriertes Spielbuch für Kinder     Spamer  1891  \n",
       "1     Illustriertes Spielbuch für Kinder     Spamer  1891  \n",
       "2     Illustriertes Spielbuch für Kinder     Spamer  1891  \n",
       "3     Illustriertes Spielbuch für Kinder     Spamer  1891  \n",
       "4     Illustriertes Spielbuch für Kinder     Spamer  1891  \n",
       "...                                  ...        ...   ...  \n",
       "1745  Illustriertes Spielbuch für Knaben     Spamer  1909  \n",
       "1746  Illustriertes Spielbuch für Knaben     Spamer  1909  \n",
       "1747  Illustriertes Spielbuch für Knaben     Spamer  1909  \n",
       "1748  Illustriertes Spielbuch für Knaben     Spamer  1909  \n",
       "1749  Illustriertes Spielbuch für Knaben     Spamer  1909  \n",
       "\n",
       "[1750 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame.from_dict(rows)\n",
    "df.to_csv(analysisPath+\"edition_vis.csv\",sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f285a5",
   "metadata": {},
   "source": [
    "The resulting CSV file can be used directly with a Vikus viewer instance. Details on how to obtain and configure Vikus can be found in a [separate repository](https://github.com/cpietsch/vikus-viewer).\n",
    "\n",
    "The config files for this visualization are available in the [vikus_config](./vikus_config/) subdirectory. These files have to be stored along with all data in the [vikus_deploy](./vikus_deploy/) subdirectory.\n",
    "\n",
    "Please note that the sample configuration assumes the Vikus sprites and thumbnails created by the [script](https://github.com/cpietsch/vikus-viewer-script) are placed under `./data/edition_vis_kids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209dacc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
